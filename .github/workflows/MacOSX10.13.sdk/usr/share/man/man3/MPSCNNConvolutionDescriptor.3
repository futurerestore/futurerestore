.TH "MPSCNNConvolutionDescriptor" 3 "Sun Jul 2 2017" "Version MetalPerformanceShaders-84.1" "MetalPerformanceShaders.framework" \" -*- nroff -*-
.ad l
.nh
.SH NAME
MPSCNNConvolutionDescriptor
.SH SYNOPSIS
.br
.PP
.PP
\fC#import <MPSCNNConvolution\&.h>\fP
.PP
Inherits NSObject, <NSSecureCoding>, and <NSCopying>\&.
.PP
Inherited by \fBMPSCNNDepthWiseConvolutionDescriptor\fP, and \fBMPSCNNSubPixelConvolutionDescriptor\fP\&.
.SS "Instance Methods"

.in +1c
.ti -1c
.RI "(void) \- \fBencodeWithCoder:\fP"
.br
.ti -1c
.RI "(nullable instancetype) \- \fBinitWithCoder:\fP"
.br
.ti -1c
.RI "(void) \- \fBsetBatchNormalizationParametersForInferenceWithMean:variance:gamma:beta:epsilon:\fP"
.br
.in -1c
.SS "Class Methods"

.in +1c
.ti -1c
.RI "(nonnull instancetype) + \fBcnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:neuronFilter:\fP"
.br
.ti -1c
.RI "(nonnull instancetype) + \fBcnnConvolutionDescriptorWithKernelWidth:kernelHeight:inputFeatureChannels:outputFeatureChannels:\fP"
.br
.in -1c
.SS "Properties"

.in +1c
.ti -1c
.RI "NSUInteger \fBkernelWidth\fP"
.br
.ti -1c
.RI "NSUInteger \fBkernelHeight\fP"
.br
.ti -1c
.RI "NSUInteger \fBinputFeatureChannels\fP"
.br
.ti -1c
.RI "NSUInteger \fBoutputFeatureChannels\fP"
.br
.ti -1c
.RI "NSUInteger \fBstrideInPixelsX\fP"
.br
.ti -1c
.RI "NSUInteger \fBstrideInPixelsY\fP"
.br
.ti -1c
.RI "NSUInteger \fBgroups\fP"
.br
.ti -1c
.RI "NSUInteger \fBdilationRate\fP"
.br
.ti -1c
.RI "NSUInteger \fBdilationRateX\fP"
.br
.ti -1c
.RI "NSUInteger \fBdilationRateY\fP"
.br
.ti -1c
.RI "const \fBMPSCNNNeuron\fP *__nullable \fBneuron\fP"
.br
.ti -1c
.RI "const \fBMPSCNNNeuron\fP *__nullable \fBMPSCNNNeuronType\fP \fBneuronType\fP"
.br
.ti -1c
.RI "float \fBneuronParameterA\fP"
.br
.ti -1c
.RI "float \fBneuronParameterB\fP"
.br
.ti -1c
.RI "BOOL \fBsupportsSecureCoding\fP"
.br
.in -1c
.SH "Detailed Description"
.PP 
This depends on Metal\&.framework  The \fBMPSCNNConvolutionDescriptor\fP specifies a convolution descriptor 
.SH "Method Documentation"
.PP 
.SS "+ (nonnull instancetype) cnnConvolutionDescriptorWithKernelWidth: (NSUInteger) kernelWidth(NSUInteger) kernelHeight(NSUInteger) inputFeatureChannels(NSUInteger) outputFeatureChannels"
Creates a convolution descriptor\&. 
.PP
\fBParameters:\fP
.RS 4
\fIkernelWidth\fP The width of the filter window\&. Must be > 0\&. Large values will take a long time\&. 
.br
\fIkernelHeight\fP The height of the filter window\&. Must be > 0\&. Large values will take a long time\&. 
.br
\fIinputFeatureChannels\fP The number of feature channels in the input image\&. Must be >= 1\&. 
.br
\fIoutputFeatureChannels\fP The number of feature channels in the output image\&. Must be >= 1\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
A valid \fBMPSCNNConvolutionDescriptor\fP object or nil, if failure\&. 
.RE
.PP

.SS "+ (nonnull instancetype) cnnConvolutionDescriptorWithKernelWidth: (NSUInteger) kernelWidth(NSUInteger) kernelHeight(NSUInteger) inputFeatureChannels(NSUInteger) outputFeatureChannels(const \fBMPSCNNNeuron\fP *__nullable) neuronFilter"
This method is deprecated\&. Please use neuronType, neuronParameterA and neuronParameterB properites to fuse neuron with convolution\&. 
.PP
\fBParameters:\fP
.RS 4
\fIkernelWidth\fP The width of the filter window\&. Must be > 0\&. Large values will take a long time\&. 
.br
\fIkernelHeight\fP The height of the filter window\&. Must be > 0\&. Large values will take a long time\&. 
.br
\fIinputFeatureChannels\fP The number of feature channels in the input image\&. Must be >= 1\&. 
.br
\fIoutputFeatureChannels\fP The number of feature channels in the output image\&. Must be >= 1\&. 
.br
\fIneuronFilter\fP An optional neuron filter that can be applied to the output of convolution\&. 
.RE
.PP
\fBReturns:\fP
.RS 4
A valid \fBMPSCNNConvolutionDescriptor\fP object or nil, if failure\&. 
.RE
.PP

.SS "\- (void) encodeWithCoder: (NSCoder *__nonnull) aCoder"
<NSSecureCoding> support 
.SS "\- (nullable instancetype) initWithCoder: (NSCoder *__nonnull) aDecoder"
<NSSecureCoding> support 
.SS "\- (void) setBatchNormalizationParametersForInferenceWithMean: (const float *__nonnull) mean(const float *__nonnull) variance(const float *__nullable) gamma(const float *__nullable) beta(const float) epsilon"
Adds batch normalization for inference, it copies all the float arrays provided, expecting outputFeatureChannels elements in each\&.
.PP
This method will be used to pass in batch normalization parameters to the convolution during the init call\&. For inference we modify weights and bias going in convolution or Fully Connected layer to combine and optimize the layers\&.
.PP
.PP
.nf
        w: weights for a corresponding output feature channel
        b: bias for a corresponding output feature channel
        W: batch normalized weights for a corresponding output feature channel
        B: batch normalized bias for a corresponding output feature channel


        I = gamma / sqrt(variance + epsilon), J = beta - ( I * mean )

        W = w * I
        B = b * I + J

        Every convolution has (OutputFeatureChannel * kernelWidth * kernelHeight * InputFeatureChannel) weights

        I, J are calculated, for every output feature channel separately to get the corresponding weights and bias
        Thus, I, J are calculated and then used for every (kernelWidth * kernelHeight * InputFeatureChannel)
        weights, and this is done OutputFeatureChannel number of times for each output channel.

        thus, internally, batch normalized weights are computed as:

        W[no][i][j][ni] = w[no][i][j][ni] * I[no]

        no: index into outputFeatureChannel
        i : index into kernel Height
        j : index into kernel Width
        ni: index into inputFeatureChannel

        One usually doesn't see a bias term and batch normalization together as batch normalization potentially cancels
        out the bias term after training, but in MPS if the user provides it, batch normalization will use the above 
        formula to incorporate it, if user does not have bias terms then put a float array of zeroes in the convolution
        init for bias terms of each output feature channel.


        this comes from:
        https://arxiv.org/pdf/1502.03167v3.pdf
.fi
.PP
.PP
\fBParameters:\fP
.RS 4
\fImean\fP Pointer to an array of floats of mean for each output feature channel 
.br
\fIvariance\fP Pointer to an array of floats of variance for each output feature channel 
.br
\fIgamma\fP Pointer to an array of floats of gamma for each output feature channel 
.br
\fIbeta\fP Pointer to an array of floats of beta for each output feature channel 
.br
\fIepsilon\fP A small float value used to have numerical stability in the code 
.RE
.PP

.SH "Property Documentation"
.PP 
.SS "\- dilationRate\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
dilationRate property can be used to implement dilated convolution as described in https://arxiv.org/pdf/1511.07122v3.pdf to aggregate global information in dense prediction problems\&. Dilated convolution is equivalent to performing convolution with dilated kernel of dimension kW_Dilated x kH_Dilated where 
.PP
.nf
  kW_Dilated = (kW-1)*dilationRate + 1
  kH_Dilated = (kH-1)*dilationRate + 1

.fi
.PP
.PP
A dilated kernel is formed by taking the origianl kW x kH kernel and inserting d-1 zeros between consecutive entries in each row and d-1 zero filled rows between consecutive rows\&. The kernel is centered based on kW_Dilated and kH_Dilated\&.
.PP
When dilationRate = 1, it reduces to regular convolution\&. Default value is 1\&. WARNING: Property dilationRate is deprecated and simply sets dilationRateX = dilationRateY = dilationRate Users should use new dilationRateX and dilationRateY properties to set dilation rate in each dimension independently\&. 
.SS "\- dilationRateX\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
dilationRateX property can be used to implement dilated convolution as described in https://arxiv.org/pdf/1511.07122v3.pdf to aggregate global information in dense prediction problems\&. Default value is 1\&. When set to value > 1, original kernel width, kW is dilated to 
.PP
.nf
  kW_Dilated = (kW-1)*dilationRateX + 1

.fi
.PP
.PP
by inserting d-1 zeros between consecutive entries in each row of the original kernel\&. The kernel is centered based on kW_Dilated\&. 
.SS "\- dilationRateY\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
dilationRateY property can be used to implement dilated convolution as described in https://arxiv.org/pdf/1511.07122v3.pdf to aggregate global information in dense prediction problems\&. Default value is 1\&. When set to value > 1, original kernel height, kH is dilated to 
.PP
.nf
  kH_Dilated = (kH-1)*dilationRateY + 1

.fi
.PP
.PP
by inserting d-1 rows of zeros between consecutive row of the original kernel\&. The kernel is centered based on kH_Dilated\&. 
.SS "\- groups\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
Number of groups input and output channels are divided into\&. The default value is 1\&. Groups lets you reduce the parameterization\&. If groups is set to n, input is divided into n groups with inputFeatureChannels/n channels in each group\&. Similarly output is divided into n groups with outputFeatureChannels/n channels in each group\&. ith group in input is only connected to ith group in output so number of weights (parameters) needed is reduced by factor of n\&. Both inputFeatureChannels and outputFeatureChannels must be divisible by n and number of channels in each group must be multiple of 4\&. 
.SS "\- inputFeatureChannels\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The number of feature channels per pixel in the input image\&. 
.SS "\- kernelHeight\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The height of the filter window\&. The default value is 3\&. Any positive non-zero value is valid, including even values\&. The position of the top edge of the filter window is given by offset\&.y - (kernelHeight>>1) 
.SS "\- kernelWidth\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The width of the filter window\&. The default value is 3\&. Any positive non-zero value is valid, including even values\&. The position of the left edge of the filter window is given by offset\&.x - (kernelWidth>>1) 
.SS "\- neuron\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [retain]\fP"
\fBMPSCNNNeuron\fP filter to be applied as part of convolution\&. This is applied after BatchNormalization in the end\&. Default is nil\&. This is deprecated\&. You dont need to create \fBMPSCNNNeuron\fP object to fuse with convolution\&. Use neuron properties in this descriptor\&. 
.SS "\- (float) neuronParameterA\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
Parameter 'a' for the neuron\&. Default: 1\&.0f  Please see class description for interpretation of a\&. 
.SS "\- (float) neuronParameterB\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
Parameter 'b' for the neuron\&. Default: 1\&.0f  Please see class description for interpretation of b\&. 
.SS "\- (const \fBMPSCNNNeuron\fP* __nullable \fBMPSCNNNeuronType\fP) neuronType\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The type of neuron to append to the convolution  Please see class description for a full list\&. Default is MPSCNNNeuronTypeNone\&. 
.SS "\- outputFeatureChannels\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The number of feature channels per pixel in the output image\&. 
.SS "\- strideInPixelsX\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The output stride (downsampling factor) in the x dimension\&. The default value is 1\&. 
.SS "\- strideInPixelsY\fC [read]\fP, \fC [write]\fP, \fC [nonatomic]\fP, \fC [assign]\fP"
The output stride (downsampling factor) in the y dimension\&. The default value is 1\&. 
.SS "\- (BOOL) supportsSecureCoding\fC [read]\fP, \fC [atomic]\fP, \fC [assign]\fP"
<NSSecureCoding> support 

.SH "Author"
.PP 
Generated automatically by Doxygen for MetalPerformanceShaders\&.framework from the source code\&.
